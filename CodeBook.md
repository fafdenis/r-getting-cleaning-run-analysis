# Getting and Cleaning Data Code Book

## Background Information
The dataset used for the data cleaning project represents experimental data collected by the Center for Machine Learning and Intelligence Systems. Experiments were carried out on a group of 30 volunteers tasked to perform six daily activities (walking, walking upstairs, walking downstairs, sitting, standing, laying) while wearing the Samsung Galaxy S smartphone on their waist. Sensory signals generated by body acceleration and angular velocity were extracted from the accelerometer and gyroscope embedded in the smartphone. The data obtained were randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. A full description of the dataset is available at: ["Human Activity Recognition Using Smartphones Dataset
Version 1.0"](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones).

## Data Cleaning Process
The analysis script, run_analysis.R, does a multiple set of tasks to produce a tidy dataset that can be used for further analysis.
* It reads in the training and test datasets, then creates a merged dataset called rundata. 
* The first two columns in the merged dataset are the 'subject' and 'activity'. The remaining 561 columns are labeled using the variable names extracted from the features.txt file.
* The 'activity' identifiers are replaced with labels extracted from the activity_labels.txt.
* Invalid characters, i.e. parentheses and dashes, are removed and replaced with underscores. The duplicate phrase 'BodyBody' is changed to 'Body'. Also, the prefix 'f' and 't' at the beginning of each variable name is separated from the rest of the name by an underscore. As such, each component of the variable name sperarated by the underscore identifies a characteristic of the estimation, i.e. domain signal, feature, measure, and axial-signal. 
* The data is grouped by subject and activity, then the mean is calculated for each variable and saved in a dataframe called rundata2.
* The grouped data is reshaped from wide to long with 5 variables, i.e. 'subject', 'activity', 'variable', 'value', and saved in a new dataframe called long_data.
* The columns in long_data are seperated,  i.e. the 'variable' column is split into 4 variables called 'domain', 'feature', 'measure', 'axis'. Then the 'measure' column is transposed (spread) into two columns, i.e. 'mean' and 'sd'. 
* A new tidy dataset called run_analysis.txt is created using long_data.

## Tidy Data
The tidy data or output file contains 7 variables listed below:
* _subject_ - numeric vector identifying each subject in the experiment. There are 30 subjects.
* _activity_ - character vector identifying 6 activities performed by each subject (laying, sitting, standing, walking, walking_downstairs, walking_upstairs).
* _domain_ - character vector identifying the 2 types of domain signals for each feature (timed, filtered).
* _feature_ - character vector identifying the features estimated by the accelerometer and gyroscope for 10 distinct patterns (BodyAcc, GravityAcc, BodyAccJerk, BodyGyro, BodyGyroJerk, BodyAccMag, GravityAccMag, BodyAccJerkMag, BodyGyroMag, BodyGyroJerkMag).
* _axis_ - character vector identifying the 3-axial signals in the x, y, and z directions. (Not all features have an axial signal. Those are marked NA).
* _average_ - numeric vector identifying the average of the mean measure for each subject, activity, and variable (i.e. domain, feature, and axis).
* _sd_ - numeric vector identifying the average of the standard deviation measure for each subject, activity, and variable (i.e. domain, feature, and axis).
